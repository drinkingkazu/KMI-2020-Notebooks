{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelized Batch Data Loading\n",
    "\n",
    "In this notebook we practice a Pytorch API to prepare a _batch data_ for machine learning algorithm training.\n",
    "\n",
    "## Goals\n",
    "* Learn what `DataLoader` is and how to create\n",
    "* Learn how to stream batch data using `DataLoader`\n",
    "\n",
    "First, we download a python package for the workshop and make sure it's up-to-date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "![ -d kmi ] || git clone https://github.com/drinkingkazu/kmi\n",
    "! cd kmi && git pull"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... followed by importing some libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib   # for plotting in 2D\n",
    "%matplotlib inline  \n",
    "import torch, numpy # only to set random seed (used by underlying python packages)\n",
    "import numpy as np  # only to set random seed (used by underlying python packages)\n",
    "# Set random seed\n",
    "SEED=123\n",
    "_=numpy.random.seed(SEED)\n",
    "_=torch.manual_seed(SEED)\n",
    "# Add the path for the python package downloaded\n",
    "import sys\n",
    "sys.path.insert(0, 'kmi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DataLoader`\n",
    "So whaat is it? When we train a machine learning algorithm using a stochastic gradient descent, we want to form a random subset of data, callled a _batch_, to compute the error and weight updates. Recall how our `Dataset` works: it tells you the total data size + gives an intuitive access to a data by a data index integer. A pytorch `DataLoader` takes `Dataset` instance with those features and automatize the packaging of batch data. \n",
    "\n",
    "Also we want this process to be fast such that we maximize the compute time spent for the algorithm forward and gradient calculations. `DataLoader` implements a scheme of multiple parallel workers to perform multiple batch data preparation to realize this.\n",
    "\n",
    "### Instantiation of `DataLoader`\n",
    "The instantiation is trivial through pytorch API, but here we will use another factory function from `kmi` package. The function takes a configuration parameters in the form of a python dictionary just like `Dataset`. In fact, you give both the `Dataset` and `DataLoader` configuration in a single dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kmi.iotools import loader_factory\n",
    "\n",
    "# Let's start with Dataset configuration\n",
    "dataset_config = dict(data_files = ['/scratch/workshop_2020_01/train/proton.h5','/scratch/workshop_2020_01/train/muon.h5'],\n",
    "                      dataset = 'DenseImage2D',\n",
    "                     )\n",
    "\n",
    "# Next, DataLoader configuration\n",
    "loader_config = dict( batch_size = 10,\n",
    "                      collate = 'DenseCollate',\n",
    "                      shuffle = False,\n",
    "                      num_workers = 4,\n",
    "                    )\n",
    "\n",
    "# Combine two configurations (or you could make one dict to begin with)\n",
    "loader_config.update(dataset_config)\n",
    "\n",
    "# Create a loader\n",
    "loader = loader_factory(**loader_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we introduced following configuration parameters:\n",
    "* `batch_size` ... the size of the subset data\n",
    "* `collate` ... a function specifier (via string) to define how multiple data entries should be combined\n",
    "* `shuffle` ... True means a subset consists of randomly chosen entries while False means sequential data access\n",
    "* `num_workers` ... an integer specifying the number of parallel workers to form batch data\n",
    "\n",
    "A bit more about `collate`: recall our `Dataset` returns a dict of data element for entry X specified by you (a user). When we prepare a batch data, we don't want an array of a dictionary, rather a dictionary of an array of data. This refactorization is implemented in `DenseCollate` and `SparseCollate` functions in this workshop, corresponding to `DenseImage2D` and `SparseImage` respectively\n",
    "\n",
    "## Data streaming with `DataLoader`\n",
    "So let's play with it! First of all, it has the concept of \"length\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of DataLoader: 20000\n",
      "By the way, batch size * length = 200000\n"
     ]
    }
   ],
   "source": [
    "print('length of DataLoader:',len(loader))\n",
    "print('By the way, batch size * length =', 10 * len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know, using 2 input files, the input data total statistics is 200,000 which coincides with the length of `DataLoader` instance and the batch size where the latter is the unit of batch data. **Yep, as you guessed**, `DataLoader` is iterable: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 batch data \"index\": [0 1 2 3 4 5 6 7 8 9]\n",
      "Iteration 1 batch data \"index\": [10 11 12 13 14 15 16 17 18 19]\n",
      "Iteration 2 batch data \"index\": [20 21 22 23 24 25 26 27 28 29]\n",
      "Iteration 3 batch data \"index\": [30 31 32 33 34 35 36 37 38 39]\n",
      "Iteration 4 batch data \"index\": [40 41 42 43 44 45 46 47 48 49]\n",
      "Iteration 5 batch data \"index\": [50 51 52 53 54 55 56 57 58 59]\n",
      "Iteration 6 batch data \"index\": [60 61 62 63 64 65 66 67 68 69]\n",
      "Iteration 7 batch data \"index\": [70 71 72 73 74 75 76 77 78 79]\n",
      "Iteration 8 batch data \"index\": [80 81 82 83 84 85 86 87 88 89]\n",
      "Iteration 9 batch data \"index\": [90 91 92 93 94 95 96 97 98 99]\n"
     ]
    }
   ],
   "source": [
    "# Create an iterator for playin in this notebook\n",
    "from itertools import cycle\n",
    "iter = cycle(loader)\n",
    "\n",
    "for i in range(10):\n",
    "    data = next(iter)\n",
    "    print('Iteration',i,'batch data \"index\":',data['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and this is how \"data\" looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of an image batch data (10, 192, 192)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of an image batch data',data['data'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which is, quite naturally, 10 of 192x192 images. \n",
    "\n",
    "## Exercise\n",
    "Let's end this exercise by:\n",
    "* plotting the pixel values in the whole batch \n",
    "* visualizing individual image in a batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram of pixel values\n",
    "fig,ax = plt.subplots(figsize=(12,8),facecolor='w')\n",
    "YOUR_CODE\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over images in a batch and visualize using matplotlib\n",
    "for i in len(data['data']):\n",
    "    data  = YOUR_CODE\n",
    "    label = YOUR_CODE\n",
    "    pdg   = YOUR_CODE\n",
    "    index = YOUR_CODE\n",
    "    # report + visualize\n",
    "    print('Data at index', index, 'PDG', pdg, 'label', label)\n",
    "    fig,ax = plt.subplots(figsize=(12,8),facecolor='w')\n",
    "    plt.imshow(data,origin='lower')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
